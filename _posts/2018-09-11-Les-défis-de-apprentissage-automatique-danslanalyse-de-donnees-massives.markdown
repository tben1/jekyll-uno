---
title:  "Les défis de l'apprentissage automatique dans l'analyse de données massives"
date:   2018-09-11 21:43:21
categories: [MachineLearnin]
tags: [MachineLearnin, BIGDATA]
---
![enter image description here](https://technofaq.org/wp-content/uploads/2018/01/1KzmIUYPmxgEHhXX7SlbP4w-620x350.jpeg)

L'apprentissage automatique (`Machine Learning`) est une branche de l'informatique, un domaine de l'intelligence artificielle. Il s’agit d’une méthode d’analyse de données permettant d’automatiser la création de modèles analytiques. Comme le mot l'indique, il permet également aux machines (systèmes informatiques) de tirer des leçons des données (`DATASET`), sans aide extérieure pour prendre des décisions avec un minimum d'interférences humaines.Avec l'évolution des nouvelles technologies, l'apprentissage automatique a beaucoup évolué au cours des dernières années.
 
 - [ ] **Qu'est-ce que le Big Data?**

Le `Big Data` , littéralement « grosses données », ou mégadonnées (recommandé), parfois appelées données massives, signifie trop d'informations, et l'analyse signifie l'analyse d'une grande quantité de données pour filtrer les informations. Un humain ne peut pas accomplir cette tâche efficacement dans un délai déterminé. Voici donc le moment où l'apprentissage automatique (`Machine Learning`) pour l'analyse de données volumineuses entre en jeu. Prenons un exemple. Supposons que vous soyez propriétaire de l’entreprise et que vous devez collecter une grande quantité d’informations, ce qui est très difficile en soi. Ensuite, vous commencez à trouver un indice qui vous aidera dans votre entreprise ou vous aidera à prendre des décisions plus rapidement. Ici, vous réalisez que vous avez affaire à d’immenses informations. Votre analyse a besoin d’un peu d’aide pour réussir votre recherche. Dans le processus d’apprentissage automatique, plus les données que vous fournissez au système sont nombreuses (`DATASET`), plus le système peut en tirer des enseignements et renvoyer toutes les informations que vous cherchiez afin que votre recherche aboutisse. C'est pourquoi cela fonctionne si bien avec l'analyse de données volumineuses. Sans `Big Data`, il ne peut pas fonctionner à son niveau optimal car avec moins de données, le système n'a que peu d'exemples à apprendre. On peut donc dire que le `Big Data` joue un rôle majeur dans l’apprentissage automatique (`Machine Learning`).

**S’il existe divers avantages de l’apprentissage automatique en analytique, il existe également divers défis. Laissez-nous en discuter un par un:**

***Apprendre à  partir des de données massives:*** avec les progrès technologiques, la quantité de données que nous traitons augmente de jour en jour. En novembre 2017, il a été constaté que Google traitait env. 25    Peta Byte par jour, avec le temps, les entreprises traverseront ces pétaoctets de données. Le principal attribut des données est Volume. Il est donc difficile de traiter une telle quantité d’informations. **Pour surmonter ce défi, les infrastructures distribuées avec l'informatique parallèle doivent être élever.**
![enter image description here](https://pbs.twimg.com/media/DFCyLpOWAAAC73q.jpg)
***Apprentissage de différents types de données:*** Il existe une grande variété de données dans les données actuelles. La variété est également un attribut majeur du Big Data. Structurés, non structurés et semi-structurés sont trois types de données différents qui entraînent en outre la génération de données hétérogènes, non linéaires et de grande dimension. Apprendre d'un tel ensemble de données constitue un défi et se traduit par une complexité accrue des données. **Pour surmonter ce défi, l’intégration de données doit être utilisée.**
![enter image description here](https://miro.medium.com/max/1400/1*W8JwjcT2OuZp5WMhKZ-Cuw.png)
***Apprentissage de la transmettre simultanément de données à grande vitesse:*** Il existe diverses tâches qui incluent l'achèvement des travaux dans un certain laps de temps. La vélocité est également l'un des principaux attributs du Big Data. Si la tâche n'est pas terminée dans un délai spécifié, les résultats du traitement risquent de perdre de la valeur ou même de perdre de leur valeur. Pour cela, vous pouvez prendre l'exemple de la prévision boursière, de la prévision des tremblements de terre, etc. Il est donc très difficile de traiter les données massives à temps. **Pour surmonter ce défi, une approche d'apprentissage en ligne devrait être utilisée.**

***Apprentissage de données ambiguës et incomplètes:*** Auparavant, les algorithmes d’apprentissage automatique disposaient de données relativement précises. Les résultats étaient donc également exacts à ce moment-là. Mais de nos jours, les données sont ambiguës car elles proviennent de différentes sources, incertaines et incomplètes. Il s’agit donc d’un défi majeur pour l’apprentissage automatique en analyse de données volumineuses. Un exemple de données incertaines sont les données générées dans les réseaux sans fil à cause du bruit, des ombrages, des évanouissements, etc. **Pour surmonter ce défi, une approche basée sur la distribution doit être utilisée.**

***Apprentissage de données de faible densité:*** L’apprentissage automatique pour l’analyse de données volumineuses a pour objectif principal d’extraire les informations utiles d’une grande quantité de données à des fins commerciales. La valeur est l'un des principaux attributs des données. Il est très difficile de trouver la valeur significative de gros volumes de données ayant une densité faible. Il s’agit donc d’un défi majeur pour l’apprentissage automatique en analyse de données volumineuses. **Pour surmonter ce défi, il convient d’utiliser les technologies d’exploration de données et la découverte de connaissances dans des bases de données.**

Les différents défis de l’apprentissage automatique dans l’analyse de données volumineuses sont analysés ci-dessus et doivent être traités avec beaucoup de soin. Il y a tellement de produits d'apprentissage automatique qu'il faut les former avec une grande quantité de données. Pour que les modèles d’apprentissage automatique soient précis, il est nécessaire de les former avec des informations historiques structurées, pertinentes et précises. Comme il y a tant de défis mais ce n'est pas impossible.
